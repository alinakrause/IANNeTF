{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a868e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736bec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 14:23:10.814281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 14:23:10.816648: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# 1. get mnist from tensorflow_datasets\n",
    "mnist = tfds.load(\"mnist\", split =[\"train\",\"test\"], as_supervised=True)\n",
    "train_ds = mnist[0]\n",
    "val_ds = mnist[1]\n",
    "\n",
    "# 2. write function to create the dataset that we want\n",
    "def preprocess(data, batch_size):\n",
    "    # image should be float\n",
    "    data = data.map(lambda x, t: (tf.cast(x, float), t))\n",
    "    # image should be flattened\n",
    "    data = data.map(lambda x, t: (tf.reshape(x, (-1,)), t))\n",
    "    # image vector will here have values between -1 and 1\n",
    "    data = data.map(lambda x,t: ((x/128.)-1., t))\n",
    "    # we want to have two mnist images in each example\n",
    "    # this leads to a single example being ((x1,y1),(x2,y2))\n",
    "    zipped_ds = tf.data.Dataset.zip((data.shuffle(2000), \n",
    "                                     data.shuffle(2000)))\n",
    "    # map ((x1,y1),(x2,y2)) to (x1,x2, y1==y2*) *boolean\n",
    "    zipped_ds = zipped_ds.map(lambda x1, x2: (x1[0], x2[0], x1[1]==x2[1]))\n",
    "    # transform boolean target to int\n",
    "    zipped_ds = zipped_ds.map(lambda x1, x2, t: (x1,x2, tf.cast(t, tf.int32)))\n",
    "    # batch the dataset\n",
    "    zipped_ds = zipped_ds.batch(batch_size)\n",
    "    # prefetch\n",
    "    zipped_ds = zipped_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return zipped_ds\n",
    "\n",
    "train_ds = preprocess(train_ds, batch_size=32) #train_ds.apply(preprocess)\n",
    "val_ds = preprocess(val_ds, batch_size=32) #val_ds.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9346a18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784) (32, 784) (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 14:23:22.440064: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-11-23 14:23:22.442298: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# check the contents of the dataset\n",
    "for img1, img2, label in train_ds.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwinMNISTModel(tf.keras.Model):\n",
    "\n",
    "    # 1. constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inherit functionality from parent class\n",
    "\n",
    "        # optimizer, loss function and metrics\n",
    "        self.metrics_list = [tf.keras.metrics.BinaryAccuracy(),\n",
    "                             tf.keras.metrics.Mean(name=\"loss\")]\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        # layers to be used\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)\n",
    "        \n",
    "        self.out_layer = tf.keras.layer.Dense(1,activation=tf.nn.sigmoid)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # 2. call method (forward computation)\n",
    "    def call(self, images, training=False):\n",
    "        img1, img2 = images\n",
    "        \n",
    "        img1_x = self.dense1(img1)\n",
    "        img1_x = self.dense2(img1_x)\n",
    "        \n",
    "        img2_x = self.dense1(img2)\n",
    "        img2_x = self.dense2(img2_x)\n",
    "        \n",
    "        combined_x = tf.concat([img1_x, img2_x ], axis=1)\n",
    "        \n",
    "        return self.out_layer(combined_x)\n",
    "\n",
    "\n",
    "\n",
    "    # 3. metrics property\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        # return a list with all metrics in the model\n",
    "\n",
    "\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "\n",
    "    # 5. train step method\n",
    "    def train_step(self, data):\n",
    "        img1, img2, label = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update the state of the metrics according to loss\n",
    "        self.metrics[0].update_state(label, output)\n",
    "        self.metrics[1].update_state(loss)\n",
    "        \n",
    "        # return a dictionary with metric names as keys and metric results as values\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 6. test_step method\n",
    "    def test_step(self, data):\n",
    "        img_1, img_2, label = data\n",
    "        # same as train step (without parameter updates)\n",
    "        output = self((img_1, img_2), training=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "train_log_path = f\"logs/\"\n",
    "\n",
    "val_log_path = f\"logs/\"\n",
    "\n",
    "train_summary_writer = ...\n",
    "\n",
    "val_summary_writer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_ds, val_ds,\n",
    "                  epochs, trains_summary_writer,\n",
    "                  val_summary_writer, save_path):\n",
    "\n",
    "    # 1. iterate over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "    \n",
    "        # 2. train steps on all batches in the training data\n",
    "        for data in tqdm.tqdm(train_ds): #tqdm optional\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "\n",
    "        # 3. log and print training metrics\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(name=\"binary_accuracy\",data=metrics[\"binary_accuracy\"], step=e)\n",
    "            tf.summary.scalar(name=\"loss\",data=metrics[\"loss\"], step=e)\n",
    "            \n",
    "        print(metrics.items())\n",
    "\n",
    "\n",
    "        # 4. reset metric objects\n",
    "        model.reset_metrics()\n",
    "\n",
    "\n",
    "\n",
    "        # 5. evaluate on validation data\n",
    "        for data in val_ds:\n",
    "            metrics = model.test_step(data)\n",
    "\n",
    "\n",
    "        # 6. log validation metrics\n",
    "\n",
    "        with val_summary_writer.as_default():\n",
    "            tf.summary.scalar(name=\"val_binary_accuracy\",data=metrics[\"val_binary_accuracy\"], step=e)\n",
    "            tf.summary.scalar(name=\"val_loss\",data=metrics[\"val_loss\"], step=e)\n",
    "        \n",
    "        print(metrics.items())\n",
    "\n",
    "        # 7. reset metric objects\n",
    "        model.reset_metrics()\n",
    "\n",
    "    # 8. save model weights\n",
    "    model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# open the tensorboard logs\n",
    "%tensorboard --logdir logs/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. instantiate model\n",
    "model = TWINMNISTModel()\n",
    "\n",
    "# 2. choose a path to save the weights\n",
    "\n",
    "save_path = \"trained_model\"\n",
    "\n",
    "# 2. pass arguments to training loop function\n",
    "\n",
    "training_loop(model=model, \n",
    "              train_ds=train=ds, \n",
    "              epochs=5, \n",
    "              train_summary_writer=train_summary_writer, \n",
    "              val_summary_writer=val_summary_writer, \n",
    "              save_path=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
